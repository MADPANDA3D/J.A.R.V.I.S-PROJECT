# Story 006.002: Centralized Application Logging Infrastructure

## Status
üîç **Ready for Review**

## Story
**As a** DevOps team member and system administrator,  
**I want** centralized application logging infrastructure with comprehensive API, database, and third-party service monitoring,  
**so that** I can track system behavior, troubleshoot integration issues, and monitor application performance across all service layers.

## Acceptance Criteria

1. **API Request/Response Logging**: Implement comprehensive API request and response logging for all Supabase database calls, authentication requests, and external service interactions with detailed timing and payload information
2. **Database Query Tracking**: Create database query logging system that tracks Supabase PostgreSQL queries, response times, error rates, and query performance metrics with proper query sanitization
3. **Third-Party Service Monitoring**: Establish monitoring for N8N webhook calls, external API integrations, and service dependencies with failure detection and retry tracking
4. **Centralized Log Storage**: Deploy centralized logging service with structured log format, searchable storage, and configurable retention policies for development, staging, and production environments
5. **Service Integration Logging**: Implement cross-service correlation logging that tracks requests across client-side, Supabase, N8N, and webhook services with distributed tracing capabilities

## Tasks / Subtasks

- [ ] **Task 1: API Request/Response Logging Implementation** (AC: 1)
  - [ ] Create Supabase client interceptor for database query logging with request/response details
  - [ ] Implement authentication event logging for Supabase auth operations (login, logout, token refresh)
  - [ ] Add external API call logging for webhook services and third-party integrations
  - [ ] Create request correlation system with unique request IDs for distributed tracing

- [ ] **Task 2: Database Query Performance Tracking** (AC: 2)
  - [ ] Implement Supabase query logging with execution time measurement and query plan analysis
  - [ ] Add database connection monitoring with pool status and connection lifecycle tracking
  - [ ] Create query performance metrics collection with slow query detection and alerting
  - [ ] Implement query sanitization to remove sensitive data while preserving debugging information

- [ ] **Task 3: Third-Party Service Monitoring System** (AC: 3)
  - [ ] Create N8N webhook monitoring with request/response logging and failure detection
  - [ ] Implement external service health monitoring with uptime tracking and error rate calculation
  - [ ] Add retry mechanism logging for failed external service calls with backoff strategy tracking
  - [ ] Create service dependency mapping with integration health status monitoring

- [ ] **Task 4: Centralized Logging Service Deployment** (AC: 4)
  - [ ] Evaluate and deploy centralized logging solution (ELK Stack, Fluentd, or cloud service)
  - [ ] Implement structured logging format with JSON schema and standardized field naming
  - [ ] Configure log aggregation pipeline with proper routing and environment-specific storage
  - [ ] Set up log retention policies and archival strategies for different log types and environments

- [ ] **Task 5: Cross-Service Correlation and Distributed Tracing** (AC: 5)
  - [ ] Implement distributed tracing system with unique trace IDs across all service interactions
  - [ ] Create service correlation mapping for client-side actions to backend service calls
  - [ ] Add request flow visualization with service dependency tracking and performance analysis
  - [ ] Implement trace aggregation and analysis tools for troubleshooting complex integration issues

- [ ] **Task 6: Logging Dashboard and Query Interface** (AC: 4, 5)
  - [ ] Create centralized logging dashboard with search, filtering, and real-time log streaming
  - [ ] Implement log query interface with structured search capabilities and saved queries
  - [ ] Add performance analytics dashboard with API response times and error rate trends
  - [ ] Create troubleshooting workflow interface with correlation analysis and service health monitoring

## Dev Notes

### Epic 006 Context

**Centralized Logging Foundation**: This story establishes the server-side and service-level logging infrastructure that complements the client-side monitoring from Story 006.001, creating a comprehensive observability platform.

**Integration Points**: Builds on existing Supabase integration, N8N webhook system, and external service architecture to provide complete system visibility and troubleshooting capabilities.

### Technical Context

**Existing Service Infrastructure** [Source: architecture/tech-stack.md]:
- **Supabase Integration**: `@supabase/supabase-js 2.52.1` with database client and authentication services
- **Webhook Services**: N8N integration with custom webhook endpoints and external service calls
- **Service Architecture**: Docker containerization with Nginx reverse proxy and static file serving
- **External Services**: Third-party API integrations and webhook-based service communications

**Current Logging Limitations** [Source: epic-006-comprehensive-logging-infrastructure.md]:
- No accessible Docker container logs for troubleshooting
- Missing API request/response logging visibility
- No database query performance tracking
- Lack of service integration monitoring and correlation

### Architecture Integration

**Supabase Client Enhancement**:
```typescript
// Enhanced Supabase client with logging
interface LoggedSupabaseClient {
  // Database operations with logging
  from<T>(table: string): LoggedPostgrestQueryBuilder<T>;
  auth: LoggedAuthClient;
  
  // Logging configuration
  enableQueryLogging: boolean;
  logLevel: 'debug' | 'info' | 'warn' | 'error';
  correlationId?: string;
}

// Database query logging interface
interface DatabaseQueryLog {
  queryId: string;
  correlationId: string;
  table: string;
  operation: 'select' | 'insert' | 'update' | 'delete';
  query: string; // Sanitized query
  parameters: Record<string, unknown>; // Sanitized parameters
  executionTime: number;
  rowCount?: number;
  error?: string;
  timestamp: string;
  userId?: string;
}
```

**Centralized Logging Architecture**:
```typescript
// Centralized log entry interface
interface LogEntry {
  logId: string;
  correlationId: string;
  traceId: string;
  timestamp: string;
  level: 'debug' | 'info' | 'warn' | 'error' | 'critical';
  service: string;
  category: 'api' | 'database' | 'auth' | 'webhook' | 'external';
  message: string;
  metadata: Record<string, unknown>;
  userId?: string;
  sessionId?: string;
  environment: string;
}

// Service monitoring interface
interface ServiceMonitoringLog {
  serviceId: string;
  serviceName: string;
  endpoint: string;
  method: string;
  statusCode: number;
  responseTime: number;
  requestSize: number;
  responseSize: number;
  error?: string;
  retryCount?: number;
  correlationId: string;
  timestamp: string;
}
```

### Integration with Existing Systems

**Supabase Integration Enhancement** [Source: architecture/source-tree.md]:
- **Enhanced Client**: Extend `src/lib/supabase.ts` with logging interceptors and query monitoring
- **Auth Logging**: Integrate with `src/contexts/AuthContext.tsx` for authentication event logging
- **Query Tracking**: Add database query logging to all table operations and RPC calls
- **Real-time Subscriptions**: Monitor Supabase real-time subscription events and connection status

**Webhook Service Integration**:
- **N8N Monitoring**: Enhance existing webhook service integration with request/response logging
- **External API Tracking**: Add logging to all external service calls and third-party integrations
- **Service Health**: Monitor webhook endpoint availability and response times
- **Retry Tracking**: Log retry attempts, backoff strategies, and failure patterns

**Docker and Infrastructure Integration**:
- **Container Logging**: Implement container log aggregation and centralized collection
- **Nginx Logging**: Configure Nginx access logs with structured format and log rotation
- **Environment Configuration**: Environment-specific logging configuration for development, staging, and production
- **Service Discovery**: Automatic service identification and logging configuration

### File Locations and Structure

**Logging Infrastructure**:
- **Enhanced**: `src/lib/supabase.ts` - Add query logging and authentication event tracking
- **New**: `src/lib/centralizedLogging.ts` - Centralized logging service client and configuration
- **New**: `src/lib/databaseLogging.ts` - Database query logging and performance tracking
- **New**: `src/lib/serviceMonitoring.ts` - Third-party service monitoring and health tracking

**Configuration and Integration**:
- **New**: `src/config/logging.ts` - Environment-specific logging configuration
- **Enhanced**: `src/lib/webhookService.ts` - Add webhook call logging and monitoring
- **New**: `src/hooks/useServiceMonitoring.ts` - React hook for service monitoring data
- **Enhanced**: `src/main.tsx` - Initialize centralized logging service

**Dashboard Components**:
- **New**: `src/components/logging/LoggingDashboard.tsx` - Centralized logging interface
- **New**: `src/components/logging/ServiceHealthMonitor.tsx` - Service health visualization
- **New**: `src/components/logging/QueryPerformanceChart.tsx` - Database performance metrics
- **New**: `src/components/logging/DistributedTraceViewer.tsx` - Cross-service trace visualization

### Centralized Logging Service Options

**ELK Stack (Elasticsearch, Logstash, Kibana)**:
- **Elasticsearch**: Scalable search and analytics engine for log storage and indexing
- **Logstash**: Log processing pipeline with filtering, parsing, and enrichment capabilities
- **Kibana**: Visualization and dashboard interface for log analysis and monitoring
- **Deployment**: Docker Compose setup with proper security and resource configuration

**Cloud Logging Services**:
- **AWS CloudWatch Logs**: Managed logging service with real-time monitoring and alerting
- **Google Cloud Logging**: Structured logging with BigQuery integration for analytics
- **Azure Monitor Logs**: Comprehensive logging with Application Insights integration
- **Datadog Logs**: APM-integrated logging with advanced correlation and analysis

**Alternative Solutions**:
- **Fluentd**: Open-source log collector with unified logging layer
- **Grafana Loki**: Log aggregation system designed for Prometheus and Grafana integration
- **Self-hosted Solutions**: Custom logging API with database storage and search capabilities

### Technical Requirements

**Performance Requirements**:
- **Logging Overhead**: Maximum 10ms additional latency for logged operations
- **Storage Efficiency**: Compressed log storage with configurable retention and archival
- **Query Performance**: Sub-second log search and filtering for troubleshooting
- **Resource Usage**: Minimal memory and CPU impact on application performance

**Security and Privacy Requirements**:
- **Data Sanitization**: Automatic removal of sensitive data from logs (passwords, tokens, PII)
- **Access Control**: Role-based access to logs with audit trail for log access
- **Encryption**: Encrypted log transmission and storage with proper key management
- **Compliance**: Log retention and privacy compliance for applicable regulations

**Reliability Requirements**:
- **High Availability**: Redundant logging infrastructure with failover capabilities
- **Data Integrity**: Guaranteed log delivery with acknowledgment and retry mechanisms
- **Backup and Recovery**: Regular log backups with disaster recovery procedures
- **Monitoring**: Self-monitoring of logging infrastructure with health checks and alerting

### Integration Patterns

**Database Query Logging Pattern**:
```typescript
// Supabase query interceptor
const loggedSupabase = createClient(url, key, {
  global: {
    fetch: async (url, options) => {
      const startTime = Date.now();
      const correlationId = generateCorrelationId();
      
      try {
        const response = await fetch(url, options);
        await logDatabaseQuery({
          correlationId,
          url,
          method: options?.method || 'GET',
          executionTime: Date.now() - startTime,
          statusCode: response.status,
          success: response.ok
        });
        return response;
      } catch (error) {
        await logDatabaseError({
          correlationId,
          url,
          error: error.message,
          executionTime: Date.now() - startTime
        });
        throw error;
      }
    }
  }
});
```

**Service Monitoring Pattern**:
```typescript
// External service call logging
async function loggedServiceCall<T>(
  serviceName: string,
  endpoint: string,
  operation: () => Promise<T>
): Promise<T> {
  const startTime = Date.now();
  const correlationId = getCurrentCorrelationId();
  
  try {
    const result = await operation();
    await logServiceCall({
      serviceName,
      endpoint,
      correlationId,
      executionTime: Date.now() - startTime,
      success: true
    });
    return result;
  } catch (error) {
    await logServiceCall({
      serviceName,
      endpoint,
      correlationId,
      executionTime: Date.now() - startTime,
      success: false,
      error: error.message
    });
    throw error;
  }
}
```

### Testing Requirements

**Logging System Testing**:
- **Integration Testing**: Validate log generation for all service interactions and database operations
- **Performance Testing**: Measure logging overhead and ensure performance requirements are met
- **Data Validation**: Verify log data accuracy, completeness, and proper sanitization
- **Correlation Testing**: Test distributed tracing and cross-service correlation functionality

**Centralized Service Testing**:
- **Log Aggregation**: Test log collection, routing, and storage across different environments
- **Search and Query**: Validate log search functionality, filtering, and query performance
- **Retention Testing**: Test log retention policies and archival processes
- **Disaster Recovery**: Test logging service backup and recovery procedures

## Testing

### Testing Standards [Source: architecture/coding-standards.md]

**Test Framework**: Vitest + Node.js testing utilities with mock logging service integration

**Test File Locations**:
- **New**: `src/lib/__tests__/centralizedLogging.test.ts` - Centralized logging service tests
- **New**: `src/lib/__tests__/databaseLogging.test.ts` - Database query logging tests
- **New**: `src/lib/__tests__/serviceMonitoring.test.ts` - Service monitoring tests
- **Enhanced**: `src/lib/__tests__/supabase.test.ts` - Enhanced Supabase client with logging tests

**Testing Patterns**:
- **Mock Logging Services**: Create mock implementations for centralized logging service testing
- **Database Query Simulation**: Test database query logging with various query types and scenarios
- **Service Call Mocking**: Mock external service calls for monitoring and logging validation
- **Correlation Testing**: Validate distributed tracing and correlation ID propagation

**Specific Testing Requirements**:
- **API Logging**: Test comprehensive API request/response logging with proper data sanitization
- **Database Tracking**: Test query performance tracking, connection monitoring, and error logging
- **Service Monitoring**: Test third-party service monitoring, health tracking, and failure detection
- **Centralized Storage**: Test log aggregation, storage, and retrieval functionality
- **Distributed Tracing**: Test cross-service correlation and trace ID propagation

**Performance Testing**:
- **Logging Overhead**: Measure and validate logging system performance impact
- **Storage Performance**: Test log storage and retrieval performance under load
- **Query Performance**: Validate log search and filtering performance with large datasets

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-07-27 | 1.0 | Initial story creation for centralized application logging infrastructure | Bob (Scrum Master) |